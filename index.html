
<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    

    <title>Jiannan Xiang</title>

    <meta name="author" content="Jiannan Xiang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
<script type="text/javascript" src="jquery-1.12.4.min.js"></script></head>

<body data-new-gr-c-s-check-loaded="14.984.0" data-gr-ext-installed="">
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr style="padding:0px">
                <td style="padding:0px">
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:0px">
                        <tbody>
                            <tr style="padding:0px">
                                <td style="padding:2.7%;width:75%;vertical-align:middle">
                                    <p style="text-align:center">
                                        <name>Jiannan Xiang</name>
                                    </p>
                                    <p>
                                        I am a second-year PhD student at University of California, San Diego, under the supervision of Prof. <a href="http://zhiting.ucsd.edu/" target="_blank">Zhiting Hu</a>. Previously, I got my Master's degree from Machine Learning Department at Carnegie Mellon University, and my Bachelor's degree in Electronic Information Engineering from University of Science and Technology of China.
                                    </p>
                                    <p>
                                        Email: jixiang[at]ucsd.edu
                                    </p>
                                    <p style="text-align:left">
                                        <a href="https://github.com/szxiangjn" target="_blank">
                                        Github</a> &nbsp;&nbsp;/&nbsp;&nbsp;
                                        <a href="https://scholar.google.com/citations?user=l8BS2wsAAAAJ&hl=en" target="_blank">
                                        Google Scholar</a> &nbsp;&nbsp;/&nbsp;&nbsp; 
                                        <a href="https://twitter.com/szxiangjn" target="_blank">
                                        Twitter</a> &nbsp;&nbsp;/&nbsp;&nbsp;
                                        <a href="https://www.linkedin.com/in/jiannan-xiang-0689281b7/" target="_blank">
                                        LinkedIn</a> &nbsp;&nbsp;&nbsp;&nbsp;
                                    </p>
                                </td>
                                <td style="padding:2%;width:40%;max-width:40%">
                                    <a><img style="width:120%;max-width:120%" alt="profile photo" src="photo.jpg" class="hoverZoomLink"></a>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Publications</heading> (* equal contribution)
                                    <p>
                                        <a href="https://research.nvidia.com/publication/2025-03_nvidia-isaac-gr00t-n1-open-foundation-model-humanoid-robots" target="_blank"><papertitle>GR00T N1: An Open Foundation Model for Generalist Humanoid Robots</papertitle></a>
                                        <br>
                                        <strong>NVIDIA (Core Contributor)</strong>&nbsp;
                                        <br>
                                        <em>Whitepaper</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://research.nvidia.com/publication/2025-03_nvidia-isaac-gr00t-n1-open-foundation-model-humanoid-robots" target="_blank">paper</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a href="https://developer.nvidia.com/blog/accelerate-generalist-humanoid-robot-development-with-nvidia-isaac-gr00t-n1/" target="_blank">blog</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a href="https://github.com/NVIDIA/Isaac-GR00T" target="_blank">code</a>&nbsp;&nbsp;
                                        <br>
                                    </p>
                                    <p>
                                        <a href="https://world-model.maitrix.org/assets/pandora.pdf" target="_blank"><papertitle>Pandora: Towards General World Model with Natural Language Actions and Video States</papertitle></a>
                                        <br>
                                        <strong>Jiannan Xiang*</strong>,&nbsp;
                                        <a href="https://guangyliu.github.io/" target="_blank">Guangyi Liu*</a>,&nbsp;
                                        <a href="https://www.yigu.page/" target="_blank">Yi Gu*</a>,&nbsp;
                                        Qiyue Gao,&nbsp;
                                        <a href="https://nnnyt.github.io/" target="_blank">Yuting Ning</a>,&nbsp;
                                        <a href="https://yuh-zha.github.io/" target="_blank">Yuheng Zha</a>,&nbsp;
                                        <a href="https://www.linkedin.com/in/zeyu-feng-1800831a1/" target="_blank">Zeyu Feng</a>,&nbsp;
                                        <a href="https://www.taotianhua.com/" target="_blank">Tianhua Tao</a>,&nbsp;
                                        <a href="https://ber666.github.io/" target="_blank">Shibo Hao</a>,&nbsp;
                                        <a href="http://scholar.pku.edu.cn/shiyemin/home" target="_blank">Yemin Shi</a>,&nbsp;
                                        <a href="https://hunterhector.github.io/" target="_blank">Zhengzhong Liu</a>,&nbsp;
                                        <a href="http://www.cs.cmu.edu/~epxing/" target="_blank">Eric P. Xing</a>,&nbsp;
                                        <a href="http://zhiting.ucsd.edu/" target="_blank">Zhiting Hu</a>&nbsp;
                                        <br>
                                        <em>Technical Report</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://world-model.maitrix.org/assets/pandora.pdf" target="_blank">paper</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a href="https://world-model.ai" target="_blank">website</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a href="https://github.com/maitrix-org/Pandora" target="_blank">code</a>&nbsp;&nbsp;
                                        <br>
                                    </p>
                                    <p>
                                        <a href="https://arxiv.org/abs/2401.08743" target="_blank"><papertitle>MMToM-QA: Multimodal Theory of Mind Question Answering</papertitle></a>
                                        <br>
                                        <a href="https://chuanyangjin.com/" target="_blank">Chuanyang Jin</a>,&nbsp;
                                        <a href="https://www.linkedin.com/in/yutong-wu-a5a575209/" target="_blank">Yutong Wu</a>,&nbsp;
                                        <a href="https://www.linkedin.com/in/jingcao26/" target="_blank">Jing Cao</a>,&nbsp;
                                        <strong>Jiannan Xiang</strong>,&nbsp;
                                        <a href="https://yenlingkuo.com/" target="_blank">Yen-Ling Kuo</a>,&nbsp;
                                        <a href="http://zhiting.ucsd.edu/" target="_blank">Zhiting Hu</a>,&nbsp;
                                        <a href="https://www.tomerullman.org/" target="_blank">Tomer Ullman</a>,&nbsp;
                                        <a href="https://groups.csail.mit.edu/vision/torralbalab/" target="_blank">Antonio Torralba</a>,&nbsp;
                                        <a href="https://web.mit.edu/cocosci/josh.html" target="_blank">Joshua B. Tenenbaum</a>,&nbsp;
                                        <a href="https://www.tshu.io/" target="_blank">Tianmin Shu</a>&nbsp;
                                        <br>
                                        <em>ACL 2024</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://arxiv.org/abs/2401.08743" target="_blank">paper</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a href="https://github.com/chuanyangjin/MMToM-QA" target="_blank">code</a>&nbsp;&nbsp;
                                        <br>
                                    </p>
                                    <p>
                                        <a href="https://arxiv.org/abs/2305.10626" target="_blank"><papertitle>Language Models Meet World Models: Embodied Experiences Enhance Language Models</papertitle></a>
                                        <br>
                                        <strong>Jiannan Xiang*</strong>,&nbsp;
                                        Tianhua Tao*,&nbsp;
                                        <a href="https://www.yigu.page/" target="_blank">Yi Gu</a>,&nbsp;
                                        <a href="https://www.tshu.io/" target="_blank">Tianmin Shu</a>,&nbsp;
                                        <a href="https://zwcolin.github.io/" target="_blank">Zirui Wang</a>,&nbsp;
                                        <a href="https://www.cs.cmu.edu/~zichaoy/" target="_blank">Zichao Yang</a>,&nbsp;
                                        <a href="http://zhiting.ucsd.edu/" target="_blank">Zhiting Hu</a>
                                        <br>
                                        <em>NeurIPS 2023</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://arxiv.org/abs/2305.10626" target="_blank">paper</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a href="https://github.com/szxiangjn/world-model-for-language-model" target="_blank">code</a>&nbsp;&nbsp;
                                        <br>
                                    </p>
                                    <p>
                                        <a href="https://arxiv.org/abs/2210.04325" target="_blank"><papertitle>ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models</papertitle></a>
                                        <br>
                                        <strong>Jiannan Xiang</strong>,&nbsp;
                                        <a href="https://hunterhector.github.io/" target="_blank">Zhengzhong Liu</a>,&nbsp;
                                        Yucheng Zhou,&nbsp;
                                        <a href="http://www.cs.cmu.edu/~epxing/" target="_blank">Eric P. Xing</a>,&nbsp;
                                        <a href="http://zhiting.ucsd.edu/" target="_blank">Zhiting Hu</a>&nbsp;
                                        <br>
                                        <em>EMNLP 2022, Findings</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://arxiv.org/abs/2210.04325" target="_blank">paper</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a href="https://github.com/szxiangjn/any-shot-data2text" target="_blank">code</a>&nbsp;&nbsp;
                                        <br>
                                    </p>
                                    <p>
                                        <a href="https://arxiv.org/abs/2203.15858" target="_blank"><papertitle>Investigating Data Variance in Evaluations of Automatic Machine Translation Metrics</papertitle></a>
                                        <br>
                                        <strong>Jiannan Xiang</strong>,&nbsp;
                                        <a href="https://sites.google.com/view/huayangli" target="_blank">Huayang Li</a>,&nbsp;
                                        <a href="https://yhlleo.github.io/" target="_blank">Yahui Liu</a>,&nbsp;
                                        <a href="https://lemaoliu.github.io/homepage/" target="_blank">Lemao Liu</a>,&nbsp;
                                        <a href="https://scholar.google.com/citations?user=xSkkA7UAAAAJ&hl=en&oi=ao" target="_blank">Guoping Huang</a>,&nbsp;
                                        <a href="http://staff.ustc.edu.cn/~liandefu/" target="_blank">Defu Lian</a>,&nbsp;
                                        <a href="https://www.linkedin.com/in/shumingshi/?originalSubdomain=cn" target="_blank">Shuming Shi</a>&nbsp;
                                        <br>
                                        <em>ACL 2022, Findings</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://arxiv.org/abs/2203.15858" target="_blank">paper</a>&nbsp;&nbsp;
                                        <br>
                                    </p>
                                    <p>
                                        <a href="https://arxiv.org/abs/2203.15860" target="_blank"><papertitle>Visualizing the Relationship Between Encoded Linguistic Information and Task Performance</papertitle></a>
                                        <br>
                                        <strong>Jiannan Xiang*</strong>,&nbsp;
                                        <a href="https://sites.google.com/view/huayangli" target="_blank">Huayang Li*</a>,&nbsp;
                                        <a href="http://staff.ustc.edu.cn/~liandefu/" target="_blank">Defu Lian</a>,&nbsp;
                                        <a href="https://scholar.google.com/citations?user=xSkkA7UAAAAJ&hl=en&oi=ao" target="_blank">Guoping Huang</a>,&nbsp;
                                        <a href="https://sites.google.com/site/tarowtnb/" target="_blank">Taro Watanabe</a>,&nbsp;
                                        <a href="https://lemaoliu.github.io/homepage/" target="_blank">Lemao Liu</a>&nbsp;
                                        <br>
                                        <em>ACL 2022, Findings</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://arxiv.org/abs/2203.15860" target="_blank">paper</a>&nbsp;&nbsp;
                                        <br>
                                    </p>
                                    <p>
                                        <a href="https://arxiv.org/abs/2105.02573" target="_blank"><papertitle>Assessing Dialogue Systems with Distribution Distances</papertitle></a>
                                        <br>
                                        <strong>Jiannan Xiang*</strong>,&nbsp;
                                        <a href="https://yhlleo.github.io/" target="_blank">Yahui Liu*</a>,&nbsp;
                                        <a href="https://jcyk.github.io/" target="_blank">Deng Cai</a>,&nbsp;
                                        <a href="https://sites.google.com/view/huayangli" target="_blank">Huayang Li</a>,&nbsp;
                                        <a href="http://staff.ustc.edu.cn/~liandefu/" target="_blank">Defu Lian</a>,&nbsp;
                                        <a href="https://lemaoliu.github.io/homepage/" target="_blank">Lemao Liu</a>&nbsp;
                                        <br>
                                        <em>ACL 2021, Findings</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://arxiv.org/abs/2105.02573" target="_blank">paper</a>&nbsp;&nbsp;/&nbsp;&nbsp;<a href="https://github.com/yhlleo/frechet-bert-distance" target="_blank">code</a>&nbsp;&nbsp;
                                        <br>
                                    </p>
                                    <p>
                                        <a href="https://arxiv.org/abs/2009.13112" target="_blank"><papertitle>Learning to stop: A Simple yet Effective Approach to Urban Vision-Language Navigation</papertitle></a>
                                        <br>
                                        <strong>Jiannan Xiang</strong>,&nbsp;
                                        <a href="https://eric-xw.github.io/" target="_blank">Xin Eric Wang</a>,&nbsp;
                                        <a href="https://sites.cs.ucsb.edu/~william/" target="_blank">William Yang Wang</a>&nbsp;
                                        <br>
                                        <em>EMNLP 2020, Findings</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://arxiv.org/abs/2009.13112" target="_blank">paper</a>&nbsp;&nbsp;
                                        <br>
                                    </p>
                                    <p>
                                        <a href="https://vigilworkshop.github.io/static/papers-2019/5.pdf" target="_blank"><papertitle>Not All Actions Are Equal: Learning to Stop in Language-Grounded Urban Navigation</papertitle></a>
                                        <br>
                                        <strong>Jiannan Xiang</strong>,&nbsp;
                                        <a href="https://eric-xw.github.io/" target="_blank">Xin Eric Wang</a>,&nbsp;
                                        <a href="https://sites.cs.ucsb.edu/~william/" target="_blank">William Yang Wang</a>&nbsp;
                                        <br>
                                        <em>NeurIPS 2019, ViGIL workshop</em>&nbsp;&nbsp;
                                        <br>
                                        <a href="https://vigilworkshop.github.io/static/papers-2019/5.pdf" target="_blank">paper</a>&nbsp;&nbsp;
                                        <br>
                                    </p>
                                </td>
                            </tr>      
                        </tbody>
                    </table>
                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Services</heading>
                                    <p>
                                        <li class="paper"> Reviewers: NeurIPS 2023, ACL 2023, AAAI 2023, EMNLP 2022, ACL ARR 2022, ACL ARR 2021.
                                        </li>
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td style="padding:0px">
                                    <br>
                                    <br>
                                    <div>
                                        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=HSpqMyQrjFG9LeWo3zlULzY-wpHMPU_BO8Vr-_VcO1M&cmn=3acc3a&cmo=ff5353&co=2d78ad&ct=ffffff'></script>
                                    </div>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td style="padding:0px">
                                    <p font-size:small;="">
                                        <br>
                                        <br>
                                        </p><div style="float:left;">
                                            Updated at May 2024
                                        </div>
                                        <div style="float:right;">
                                            Thanks <a href="https://jonbarron.info/">Jon Barron</a> for this amazing work
                                        </div>
                                        <br>
                                        <br>        
                                    <p></p>                           
                                </td>
                            </tr>
                        </tbody>
                    </table>
                </td>
            </tr>
    </tbody></table>

<div class="jvectormap-tip"></div></body></html>
